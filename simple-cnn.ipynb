{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Template code for CNN\n\nIn this notebook, we will show a simple usage of CNN on the MNIST dataset. \nThe usage of GPUs is highly recommended","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.datasets as datasets\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader\nimport torch.optim as optim\nfrom math import floor\n\n# Set torch seed\ntorch.manual_seed(0)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Even before...\n\nBe sure you have understood what happens here!","metadata":{}},{"cell_type":"code","source":"C_in = 3\nC_out = 4\nH = 5\nW = 5\nd = 2\nbias_flag = False\n\nX = torch.randint(0, 10, (C_in,H , W), dtype=torch.float32)\nf = torch.nn.Conv2d(in_channels=C_in, out_channels=C_out, kernel_size=d, bias=bias_flag)\nY = f(X)\nprint(Y.shape)\nfor x in f.parameters():\n    print(x)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Dataset\nFirst, we load the [MNIST dataset](https://pytorch.org/vision/main/generated/torchvision.datasets.MNIST.html) directly from PyTorch. As usual, we split data within train, evaluation and test. Then, we create the `Dataloader` object","metadata":{}},{"cell_type":"code","source":"dataset_train = datasets.MNIST('.', train=True, download=True, transform=transforms.ToTensor()) # download = True just once\ndataset_test = datasets.MNIST('.', train=False, download=True, transform=transforms.ToTensor())\n\ndataset_validation, dataset_test = torch.utils.data.random_split(dataset_test, [0.5, 0.5])\nprint(\"We have\", len(dataset_validation), \"items for validation and\", len(dataset_test), \"items for test\")\n\nbatch_size = 32 # Reduce it in case you need it\n\ntrain_loader = DataLoader(dataset_train, batch_size=batch_size)\nvalidation_loader = DataLoader(dataset_validation, batch_size=len(dataset_validation))\ntest_loader = DataLoader(dataset_test, batch_size=len(dataset_test))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model\n\nDefine a simple Convolutional neural network having 3 conv + pool layers. As activation function, use ReLu","metadata":{}},{"cell_type":"code","source":"def out_dimensions(conv_layer, h_in, w_in):\n    '''\n    This function computes the output dimension of each convolutional layers in the most general way. \n    See here https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n    '''\n    h_out = floor((h_in + 2 * conv_layer.padding[0] - conv_layer.dilation[0] * (conv_layer.kernel_size[0] - 1) - 1) /\n                  conv_layer.stride[0] + 1)\n    w_out = floor((w_in + 2 * conv_layer.padding[1] - conv_layer.dilation[1] * (conv_layer.kernel_size[1] - 1) - 1) /\n                  conv_layer.stride[1] + 1)\n    return h_out, w_out\n    \nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n        h_out, w_out = out_dimensions(self.conv1, 28, 28)\n        self.conv2 = nn.Conv2d(32, 32, kernel_size=3)\n        h_out, w_out = out_dimensions(self.conv2, h_out, w_out)\n        self.pool1 = nn.MaxPool2d(2, 2)\n        h_out, w_out = h_out // 2, w_out // 2\n        self.dropout1 = nn.Dropout2d(p=0.3)\n\n        self.conv3 = nn.Conv2d(32, 64, kernel_size=3)\n        h_out, w_out = out_dimensions(self.conv3, h_out, w_out)\n        self.conv4 = nn.Conv2d(64, 64, kernel_size=3)\n        h_out, w_out = out_dimensions(self.conv4, h_out, w_out)\n        self.pool2 = nn.MaxPool2d(2, 2)\n        h_out, w_out = h_out // 2, w_out // 2\n        self.dropout2 = nn.Dropout2d(p=0.4)\n\n        self.fc1 = nn.Linear(64 * h_out * w_out, 128)\n        self.fc2 = nn.Linear(128, 10)\n        self.dropout_fc = nn.Dropout(p=0.5)\n\n        self.dimensions_final = (64, h_out, w_out)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = self.pool1(x)\n        x = self.dropout1(x)\n\n        x = F.relu(self.conv3(x))\n        x = F.relu(self.conv4(x))\n        x = self.pool2(x)\n        x = self.dropout2(x)\n\n        n_channels, h, w = self.dimensions_final\n        x = x.view(-1, n_channels * h * w)\n        x = F.relu(self.fc1(x))\n        x = self.dropout_fc(x)\n        x = self.fc2(x)\n\n        return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"model = CNN()\nlearning_rate = 0.001\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\nloss_fn = nn.CrossEntropyLoss()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'mps' \n    if torch.backends.mps.is_available() else 'cpu')\nmodel = model.to(DEVICE)\nprint(\"Working on\", DEVICE)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"n_epochs = 5\ntrain_loss_list = []\nvalidation_loss_list = []\nfor epoch in range(n_epochs):\n    loss_train = 0\n    for data, target in train_loader:\n        # Set the model in training mode\n        model.train()\n        data, target = data.to(DEVICE), target.to(DEVICE)\n        # Set the gradient to 0\n        optimizer.zero_grad()\n        # Make a prediction\n        output = model(data)\n        # Compute the loss function\n        loss = loss_fn(output, target)\n        loss_train += loss.item()\n        # Backpropagation\n        loss.backward()\n        # Update parameters\n        optimizer.step()\n    loss_train = loss_train / len(train_loader) # Consider this alternative method of tracking training loss. \n    train_loss_list.append(loss_train)\n    \n    # At the end of every epoch, check the validation loss value\n    with torch.no_grad():\n        model.eval()\n        for data, target in validation_loader: # Just one batch\n            data, target = data.to(DEVICE), target.to(DEVICE)\n            # Make a prediction\n            output = model(data)\n            # Compute the loss function\n            validation_loss = loss_fn(output, target).item()\n            print(f\"Epoch {epoch + 1}: Train loss: {loss_train}, Validation loss {validation_loss}\")\n            validation_loss_list.append(validation_loss)\n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure()\nplt.plot(range(n_epochs), train_loss_list)\nplt.plot(range(n_epochs), validation_loss_list)\nplt.legend([\"Train loss\", \"Validation Loss\"])\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss value\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Test\n\nIn this section, we test our model on new data by computing the accuracy","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    n_correct = 0\n    n_samples = 0\n    for data, target in test_loader:\n        data, target = data.to(DEVICE), target.to(DEVICE)\n        outputs = model(data)\n        _, predicted = torch.max(outputs.data, 1)\n        n_samples += target.size(0)\n        n_correct += (predicted == target).sum().item()\n\n    acc = 100.0 * n_correct / n_samples\nprint(\"Accuracy on the test set:\", acc, \"%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}